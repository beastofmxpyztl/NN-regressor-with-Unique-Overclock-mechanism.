import numpy as np

class NeuralRegressor:
    def __init__(self, x, y, hidden_neurons=10, lr=0.1):
        self.x = np.array(x)
        self.y = np.array(y)
        self.lr = lr

        self.n_samples, self.n_features = self.x.shape
        self.hidden_neurons = hidden_neurons
        self.n_output = 1
        self.max_grad = 3


        self.w1 = np.random.randn(self.n_features, hidden_neurons) * np.sqrt(2 / self.n_features)
        self.b1 = np.zeros((1, hidden_neurons))

        self.w2 = np.random.randn(hidden_neurons, self.n_output) * np.sqrt(2 / hidden_neurons)
        self.b2 = np.zeros((1, self.n_output))




    def sigmoid(self, x):
        return 1/(1+np.exp(-x))

    def swish(self, x):
        return x * self.sigmoid(x)

    def swish_derivative(self,x):
        sig = self.sigmoid(x)
        return sig + x * sig * (1 - sig)

    def train(self,overclock_time,overclock_amount, epochs=1000, epoch_alarm=1000):
        count = 1
        max_grad = self.max_grad
        for epoch in range(epochs):

            z1 = self.x @ self.w1 + self.b1
            a1 = self.swish(z1)
            yhat = a1 @ self.w2 + self.b2

            if (epoch%epoch_alarm==0):
                print('Epoch:',epoch,'|| Loss:',np.mean((yhat-self.y)**2))


            if (epoch != 0 and epoch%overclock_time == 0 and count == 1):
                self.lr += overclock_amount
                count = 2
                print('New lr:',self.lr)

            m = self.x.shape[0]
            error = (yhat - self.y) * 1/m
            dw2 = a1.T @ error
            db2 = np.sum(error, axis=0, keepdims=True)

            da1 = error @ self.w2.T
            dz1 = da1 * self.swish_derivative(z1)
            dw1 = self.x.T @ dz1
            db1 = np.sum(dz1, axis=0, keepdims=True)

            dw2 = np.clip(dw2, -max_grad, max_grad)
            db1 = np.clip(db1,-max_grad, max_grad)
            dw1 = np.clip(dw1,-max_grad,max_grad)
            db2 = np.clip(db2,-max_grad, max_grad)


            self.w1 -= self.lr * dw1
            self.b1 -= self.lr * db1
            self.w2 -= self.lr * dw2
            self.b2 -= self.lr * db2

    def predict(self, x):
        x = np.array(x)
        z1 = x @ self.w1 + self.b1
        a1 = self.swish(z1)
        yhat = a1 @ self.w2 + self.b2
        return yhat
